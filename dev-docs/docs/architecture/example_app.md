# An example app architecture

``` mermaid
architecture-beta
    group intranet(cloud)[DT platform]
    group group1[Service] in intranet

    service proxy(server)[HTTP entrypoint] in intranet
    service auth(server)[Authentication server] in intranet

    service db(database)[Database] in group1
    service server(server)[API Server] in group1
    service frontend(server)[Frontend static server] in group1
    service jobq(database)[Job queue] in group1

    junction j1 in intranet
    junction j2 in intranet
    junction j3 in intranet

    service person(internet)[End user]
    service sensor(internet)[Sensors]
    service mqtt(server)[MQTT broker] in intranet
    service mqttclient(server)[MQTT client] in group1
    service worker(server)[Workers] in group1

    sensor:L--R:mqtt
    mqtt:L--R:mqttclient

    person:B--T:j1
    j1:B--T:proxy
    proxy:L--R:auth
    proxy:R--L:server
    proxy:B--T:j2
    j2:R--L:frontend
    server:R--L:db
    jobq:R--L:worker
    server:T--B:jobq
    worker:B--T:db
    db:B--T:mqttclient
```

The diagram above shows an example service in the DT plaform.  The service is accessed by the end user via a common entry point (provided by Traefik), which handles the authentication step and forwards HTTP requests to the appropriate server.

## Frontend

- This can be a simple webserver for serving **static HTML+CSS+JS**
- For consistent styling, we will use [Mantine with Vite](https://mantine.dev/guides/vite/) with common `AppShell` headers and footers; see the `dt-demo-gcp-login` subproject for an example.
- The frontend content is static, thus the frontend server does not commnicate with the API server; instead, the **client** (end user) will make any API calls necessary to "hydrate" the static content and execute any callbacks.

## API server

- Will typically be FastAPI
- Service discovery will be done by Traefik, API discovery by checking the service's `openapi.json` file
    - `openapi.json` is automatically generated by FastAPI and similar tools and **must be present** for DT platform self-documentation purposes

## Database

- Shown above as part of the service; however, services may use a central database, a service-specific database, or any combination of the two
- Data synchronziation between service and central database???
- Multiple databases may be used based on need (e.g. Postgres, Neo4j, InfluxDB).  Alternatively, extensions may be installed to extend Postgres, see the [Docker Hub documentation](https://hub.docker.com/_/postgres/#additional-extensions) on how to extend the base Postgres image.

## MQTT

A shared MQTT broker can be used to ingest sensor data and allow for event-driven communication between services.  In the illustrated example above, sensor data is used to update the service's databases; this data may be fetched by the API server later.

### MQTT Security

???

## Workers

The API server should always respond to the end user as quickly as possible.  For long-running tasks, the API server can pass off computation to a Worker, then return `HTTP 202 Accepted` to signal that job processing has begun, along with a Job ID.  It is then up to the client to poll for the job status and (if completed) result.

For job management, we can use the [`rq`](https://python-rq.org/) Python library, which is Redis-based.  Thus, the API server (and possibly the MQTT client) can place jobs in the job queue, which are automatically processed by the workers in order (unless expired).

!!! note

    Set the `ttl` for RQ jobs to prevent execution of stale jobs.  See the [Job Creation](https://python-rq.org/docs/jobs/#job-creation) documentation for RQ.
